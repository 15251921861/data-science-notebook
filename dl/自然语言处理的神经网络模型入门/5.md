# 五、词嵌入

神经网络方法的一个主要组成部分是嵌入的使用 - 将每个特征表示为低维空间中的向量。 但向量从哪里来？ 本节将综述常用方法。

## 5.1 随机初始化

当有足够可用的监督训练数据时，可以将特征嵌入视为与其他模型参数：将嵌入向量初始化为随机值，并让网络训练过程将它们调整为“好的”向量。 随机初始化必须小心执行。 有效的 word2vec 实现（Mikolov 等，2013; Mikolov，Sutskever，Chen，Corrado 和 Dean，2013）使用的方法是，将单词向量初始化为范围 $[-\frac{1}{2d},\frac{1}{2d}]$ 其中`d`是维数。 另一种选择是使用 xavier 初始化（请参阅第 6.3 节），并使用均匀采样的值进行初始化，它来自 $[-\frac{\sqrt 6}{\sqrt d},\frac{\sqrt 6}{\sqrt d}]$。

实际上，人们通常会使用随机初始化方法，来初始化常见特征的嵌入向量，例如词性标签或单个字母，同时使用某种形式的监督式或无监督式预训练，来初始化潜在的罕见特征 ，如单个词的特征。 然后，预训练的向量可以在网络训练过程中被视为固定的，或者更通常，像随机初始化的向量一样对待，并进一步调整到手边的任务。

## 5.2 监督的任务特定的预训练

如果我们对任务 A 感兴趣，其中我们只有有限数量的标记数据（例如句法分析），但是有一个辅助任务 B（比如说词性标注），其中我们有更多的标记数据，我们可能需要预先训练我们的单词向量，使它们可以很好地预测任务 B ，然后使用训练好的向量来训练任务 A。这样，我们就可以利用我们为任务 B 准备的大量标记数据 。当训练任务 A 时，我们可以将预训练的向量视为固定的，或者将它们进一步调整以用于任务 A。另一个选项是针对两个目标联合训练，参见第 7 节来获得更多细节。


## 5.3 无监督的预训练

常见的情况是，我们没有这样的辅助任务，它拥有足够多的标记数据（或者我们想用更好的向量训练它，来启动这个辅助任务）。 在这种情况下，我们诉诸于“无监督”的方法，这些方法可以在大量未标记的文本上训练。 训练单词向量的技术基本上是监督学习的技术，但是我们并不监督我们关心的任务，而是从原始文本中创建实际上无限数量的监督训练实例，希望我们创建的任务能够匹配（ 或者足够接近）我们关心的最终任务。

